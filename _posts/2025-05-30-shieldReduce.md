---
layout: post
title: shieldReduce
description: 还没想好
tag: 记录
---

## 关键词
去重，增量压缩，本地压缩，SGX

## 背景
### plain data（没有加密的数据），有三种数据压缩办法
- 去重:通过**分块**和**生成哈希值**来实现。fingerprint index
- 增量压缩：通过生成特征来寻找相似块，如果两个块至少有一个特征相同则它们是相似块。feature index
- 本地压缩：无损方式。不对delta chunk进行laocal compresssion,因为收效甚微。

通过file recipe来重建文件。

### 加密去重的局限
通过一种加密方式保证来自不同用户的相同块能被加密成一样，服务器端无法获得源数据也能够实现去重。
- 可能通过频率分析的方式泄露数据
- 熵值高，难以进一步压缩

在客户端压缩再加密的方式也会影响多用户之间的数据压缩。

### SGX
细粒度体现在只在一部分环境enclave可信而不是整台机器。
加密是在数据压缩之后。
在enclave中执行去重，本地压缩，增量压缩，将加密结果存放在持久存储中。

客户端分块，并通过安全会话传输chunks。

### 威胁模型
攻击者试图获得源数据。

### 挑战
- SGX的资源限制
- base chunk多，不好管理

## 要解决的问题
- 存储节约和数据安全的矛盾
- 兼容去重和细粒度数据压缩

## 所使用的办法
DEBE通过基于频率的去重减少资源开销

过去的研究通常把第一个chunk作为base chunk

使用Finesse作为相似度匹配的技术，将其他相似度匹配技术作为未来的工作。

所有几KB的chunk都被组合成几MB的container,所有I/O操作都以container为单位进行。
为了解决增量压缩时访问base chunk的I/O开销，通过双向增量压缩保持物理局部性,进而减少开销。
由于是从持久存储上加载一批base chunk，所以保持物理局部性可以减少I/O次数。
根据参数在两种增量压缩的方式之间交换，以平衡I/O开销和存储节省。

- 在线压缩办法：去重后，如果局部性存在，执行在线的前向增量压缩和本地压缩。
- 离线压缩办法：去重后，如果局部性不存在，通过离线的反向增量压缩重建局部性。

## 测试
数据集：
- 源代码版本
- 二进制快照
- 网站
- 操作系统镜像